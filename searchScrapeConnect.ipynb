{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in(email, password, PATH):\n",
    "#     this function automates login process on linkedin, \n",
    "#     provide email and password as strings\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "    time.sleep(5)\n",
    "    # webdriver gets page\n",
    "    driver.get(\"https://www.linkedin.com/\")\n",
    "    # pause for page to load\n",
    "    time.sleep(3)\n",
    "    # locate and send login email and password\n",
    "    driver.find_element_by_id(\"session_key\").send_keys(email)\n",
    "    driver.find_element_by_id(\"session_password\").send_keys(password)\n",
    "    driver.find_element_by_class_name(\"sign-in-form__submit-button\").click()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_scrape(search_term, num_pages):\n",
    "        \n",
    "#                 function to automate search bar, search focus\n",
    "#                 from your linkedin homepage, collecting data from\n",
    "#                 search including name, location(secondary_deets), \n",
    "#                 headline(primary_deets) from condensed profiles returned from\n",
    "#                 search results. requires string entry for search term\n",
    "#                 and int input for number of pages (num_pages) \n",
    "#                 that you wish to scrape from results.\n",
    "\n",
    "    # activate search bar cursor with click\n",
    "    driver.find_element_by_id(\"global-nav-search\").click()\n",
    "    # send keyboard entry for search terms\n",
    "    driver.find_element_by_css_selector(\"input.search-global-typeahead__input\").send_keys(search_term)\n",
    "    # send enter key to activate search\n",
    "    driver.find_element_by_css_selector(\"input.search-global-typeahead__input\").send_keys(Keys.RETURN)\n",
    "    # wait for results to load\n",
    "    driver.implicitly_wait(6)\n",
    "    #w.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ul.reusable-search__entity-results-list')))\n",
    "    element = driver.find_element_by_css_selector('ul.reusable-search__entity-results-list ')\n",
    "    # scroll to element containing target(people_banner)  allowing ajax elements to load\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "    driver.implicitly_wait(5)\n",
    "   # locate banner under search type results\n",
    "    people_banner = driver.find_element_by_link_text(f\"See all people results\")\n",
    "    # js function to click banner/button to see additional results under jobs, people, or posts                      \n",
    "    driver.execute_script('arguments[0].click();',people_banner)\n",
    "    # pause to allow page to load\n",
    "    driver.implicitly_wait(6)\n",
    "    # starting with pagination page 1                       \n",
    "    page_number = 1\n",
    "    # get current url for page\n",
    "    current_page_url = driver.current_url\n",
    "\n",
    "    # set while loop to define pagination and data collection conditions\n",
    "    while page_number <= num_pages:\n",
    "        print(\"Processing page: \" + str(page_number))\n",
    "    # find all results on page\n",
    "        links = driver.find_elements_by_css_selector(\"div.entity-result__content \")\n",
    "   # pause for page load\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # iterate through results\n",
    "        for l in links:\n",
    "    # retrieve profile url\n",
    "            title = l.find_element_by_css_selector(\"span.entity-result__title a.app-aware-link\")\n",
    "            profile_path = (str(title.get_attribute(\"pathname\")))\n",
    "    # add to urls list\n",
    "            url_list.append(profile_path)\n",
    "    # locating elements containing text needed\n",
    "            details = l.find_elements_by_css_selector(\"div.linked-area\")\n",
    "    # the first element has the first three lines of text in the container\n",
    "            deets = details[0]  \n",
    "    # split text to assign elements appropriately\n",
    "            text = deets.get_attribute('innerText').split('\\n')\n",
    "    # retrieve name/add to list\n",
    "            name = text[0]\n",
    "            name_list.append(name)\n",
    "    # retrieve location/add to list   \n",
    "            loc = text[-1]\n",
    "            loc_list.append(loc)\n",
    "     # retrieve headline/add to list\n",
    "            headline = text[-2]\n",
    "            headline_list.append(headline)\n",
    "    # the second element selected contains the 'Current:' job text \n",
    "            current_job = details[1]\n",
    "    # removing the 'Current:' string from text\n",
    "            current_job = current_job.get_attribute('innerText').split(':')[1]\n",
    "    # add current job to list\n",
    "            current_job_list.append(current_job)\n",
    "        time.sleep(3)\n",
    "    # navigate using pagination function\n",
    "        goto_next_page()\n",
    "        page_number+=1\n",
    "    # print to verify page during processing\n",
    "        print(f\"attempting to navigate to search results page {page_number}\")\n",
    "        time.sleep(5)\n",
    "   \n",
    "    # create dataframe with extracted information and save as csv file\n",
    "    df = pd.DataFrame()                      \n",
    "    df['name'] = name_list\n",
    "    df['url'] = url_list\n",
    "    df['current_job'] = current_job_list\n",
    "    df['location'] = loc_list\n",
    "    df['headline'] = headline_list\n",
    "    # add complete url information for use in complete profile scraping\n",
    "    for row in df:\n",
    "        df['fetch'] = 'https://www.linkedin.com' + df.url + '/'\n",
    "    df.to_csv(f'{search_term}.csv')\n",
    "    # verify save\n",
    "    print(f'{search_term}.csv saved')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_name():\n",
    "    profile_header = driver.find_element_by_css_selector(\"ul.pv-top-card--list\")\n",
    "    # find name element from profile header portion\n",
    "    header_details = profile_header.find_elements_by_tag_name(\"li\")\n",
    "    profile_name = header_details[0].get_attribute('innerText')\n",
    "    return profile_name\n",
    "\n",
    "def get_first_name():\n",
    "    full_name = get_name()\n",
    "    name = full_name.split(' ', 1)\n",
    "    first_name = name[0]\n",
    "    return first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goto_next_page():\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_css_selector('div.artdeco-pagination')\n",
    "    go_to_next = driver.find_element_by_css_selector('button[aria-label=\"Next\"]')\n",
    "    driver.execute_script('arguments[0].click();',go_to_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_element(wait_element_css, select_element):\n",
    "    w = WebDriverWait(driver, 10)\n",
    "    # choose element that will populate without scroll, otherwise, use scroll to position\n",
    "    w.until(EC.presence_of_element_located((By.CSS_SELECTOR, wait_element_css)))\n",
    "    time.sleep(5)\n",
    "    # background container\n",
    "    element = driver.find_element_by_css_selector(select_element)\n",
    "    #print(\"here\" + str(background))\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_title(container):\n",
    "    try:\n",
    "        position = container.find_element_by_tag_name(\n",
    "            'h3').get_attribute('innerText')\n",
    "    except NoSuchElementException:\n",
    "        position = 'nan'\n",
    "    return position\n",
    "\n",
    "def get_company(container):\n",
    "    try:\n",
    "        company = container.find_element_by_tag_name(\n",
    "            'p.pv-entity__secondary-title').get_attribute('innerText')\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        company = 'nan'\n",
    "    return company\n",
    "\n",
    "def get_work_location(container):\n",
    "    try:\n",
    "        location = container.find_element_by_css_selector(\n",
    "            'h4.pv-entity__location').get_attribute('innerText')\n",
    "        location = re.sub(r'[^\\w]', ' ', location)\n",
    "        location = re.sub(r'Location ', ' ', location)\n",
    "        location = location.str.strip()\n",
    "    except NoSuchElementException:\n",
    "        location = 'nan'\n",
    "    return location   \n",
    "\n",
    "def get_dates_employed(container):\n",
    "    try:\n",
    "        dates = container.find_element_by_css_selector(\n",
    "            \"h4.pv-entity__date-range\").get_attribute('innerText').split(' ', 2)[-1]\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        dates = 'nan'\n",
    "    return dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_employment(job_history_digit):\n",
    "#     argument input must be integer, gets single job info at a time, \n",
    "#     for example, want their most recent job, job_history_digit = 1, \n",
    "#     want the job before most recent, or second in list of jobs, job_history_digit = 2, etc\n",
    "    j = int(job_history_digit) - 1\n",
    "    background = go_to_element(\"div.profile-detail\", \"div[id='oc-background-section']\" )\n",
    "    time.sleep(4)\n",
    "    # locate experience section\n",
    "    try:\n",
    "        exp = background.find_element_by_css_selector(\n",
    "            \"section[id='experience-section']\")\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        pos = 'nan'\n",
    "        company = 'nan'\n",
    "        location = 'nan'\n",
    "        dates = 'nan'\n",
    "    else:\n",
    "        history = exp.find_elements_by_css_selector(\n",
    "                \"a[data-control-name='background_details_company']\")\n",
    "        details = history[j]\n",
    "        pos = get_job_title(details)\n",
    "        company = get_company(details)\n",
    "        location = get_work_location(details)\n",
    "        dates = get_dates_employed(details)\n",
    "\n",
    "    time.sleep(2)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school(school_history_digit):\n",
    "    # locate education section, this works following experience section, \n",
    "    # otherwise, must locate background element see go_to_element script above \n",
    "    s = int(school_history_digit) -1\n",
    "    try:\n",
    "        education = background.find_element_by_css_selector(\n",
    "            \"section[id='education-section']\")\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        school_name =  'nan'\n",
    "        \n",
    "    else:\n",
    "        schools = education.find_elements_by_css_selector(\n",
    "            \"a[data-control-name='background_details_school']\")\n",
    "        school = schools[s]\n",
    "        school_name = container.find_element_by_tag_name(\n",
    "        'h3').get_attribute('innerText')\n",
    "# scroll to bottom to prevent automation detection flag\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    return school_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email():\n",
    "    # scroll to top of profile where email is located\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    contact_info = driver.find_element_by_css_selector(\n",
    "        'a[data-control-name=\"contact_see_more\"]')\n",
    "    contact_info.click()\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        container =  driver.find_elements_by_css_selector(\n",
    "            'div.pv-contact-info__ci-container')\n",
    "        email =  container[1].get_attribute('innerText')\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        email = 'nan'\n",
    "    close_popup = driver.find_element_by_css_selector(\n",
    "            'button[aria-label=\"Dismiss\" ]')\n",
    "    close_popup.click()\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_connect():\n",
    "    # scroll to top of profile to ensure elements can be found by webdriver\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    # obtain name to personalize message\n",
    "    f_name = get_first_name()\n",
    "    time.sleep(2)\n",
    "    # locate & click 'Connect' button located at top of profile\n",
    "    driver.find_element_by_class_name('pv-s-profile-actions--connect').click()\n",
    "    action_bar = driver.find_element_by_css_selector(\"div.artdeco-modal__actionbar\")\n",
    "    # locate 'Add a note' button by class\n",
    "    action_bar.find_element_by_class_name('mr1').click()\n",
    "    # create message using information scraped from profile\n",
    "    message = f'''Hi {f_name}, I am a data scientist in the DC area. \n",
    "    I wanted to reach out, say hi, and connect with you'''.replace('\\n',' ')\n",
    "    time.sleep(3)\n",
    "    # action to send text from message to input box\n",
    "    message_input = driver.find_element_by_id('custom-message').send_keys(message)\n",
    "    # send the message & connection request\n",
    "    driver.find_element_by_class_name('ml1').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = sign_in('mn@gmail.com', 'S1!', PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "urls = []\n",
    "p_details = []\n",
    "s_details = []\n",
    "name_list = []\n",
    "email_list = []\n",
    "position_list = []\n",
    "company_list = []\n",
    "location_list = []\n",
    "dates_list = []\n",
    "position_list2 = []\n",
    "company_list2 = []\n",
    "location_list2 = []\n",
    "dates_list2 = []\n",
    "school_list = []\n",
    "school_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page: 1\n",
      "attempting to navigate to search results page 2\n",
      "Processing page: 2\n",
      "attempting to navigate to search results page 3\n",
      "data engineer.csv saved\n"
     ]
    }
   ],
   "source": [
    "loc_list = []\n",
    "current_job_list = []\n",
    "name_list = []\n",
    "url_list = []\n",
    "headline_list = []\n",
    "\n",
    "search_df = people_scrape('data engineer', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>current_job</th>\n",
       "      <th>location</th>\n",
       "      <th>headline</th>\n",
       "      <th>fetch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vina Zhu</td>\n",
       "      <td>/in/vina-zhu-4986451a4</td>\n",
       "      <td>Data Engineer at Slalom Build</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://www.linkedin.com/in/vina-zhu-4986451a4/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Murali Subramanian</td>\n",
       "      <td>/in/musubr0298</td>\n",
       "      <td>Data Engineer at Searce Inc</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Data Engineer at Searce Inc. | 2x GCP | 2x AWS</td>\n",
       "      <td>https://www.linkedin.com/in/musubr0298/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitthal Khaitan</td>\n",
       "      <td>/in/bitthal-khaitan-48846318</td>\n",
       "      <td>Data Engineer at CVS Health</td>\n",
       "      <td>Dallas-Fort Worth Metroplex</td>\n",
       "      <td>Data Engineer @ World’s largest Healthcare org!</td>\n",
       "      <td>https://www.linkedin.com/in/bitthal-khaitan-48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jianfang Chen</td>\n",
       "      <td>/in/jianfang-chen-2286a31b1</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>United States</td>\n",
       "      <td>Data Engineer at Microsoft</td>\n",
       "      <td>https://www.linkedin.com/in/jianfang-chen-2286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charishma Ravoori</td>\n",
       "      <td>/in/charishmar</td>\n",
       "      <td>Data Engineer at Lowe's Companies, Inc.</td>\n",
       "      <td>Germantown, MD</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://www.linkedin.com/in/charishmar/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mahdieh Taher</td>\n",
       "      <td>/in/mahdiehtaher</td>\n",
       "      <td>Data Engineer at ViacomCBS</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://www.linkedin.com/in/mahdiehtaher/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alper Tosun</td>\n",
       "      <td>/in/alper-tosun-bba82467</td>\n",
       "      <td>Data Management Analyst at Fannie Mae - ...th...</td>\n",
       "      <td>Washington DC-Baltimore Area</td>\n",
       "      <td>Data Engineer at Fannie Mae</td>\n",
       "      <td>https://www.linkedin.com/in/alper-tosun-bba82467/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alexandra Putilina</td>\n",
       "      <td>/in/putilinaa</td>\n",
       "      <td>Data Engineer Fellow at Insight Data Science</td>\n",
       "      <td>Greater Seattle Area</td>\n",
       "      <td>Data Engineer at H-E-B</td>\n",
       "      <td>https://www.linkedin.com/in/putilinaa/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asfetaw Abera</td>\n",
       "      <td>/in/asfetaw-abera-54b0a2185</td>\n",
       "      <td>Data Science Fellow at The Data Incubator - C...</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>Data Engineer at Caris Life Sciences</td>\n",
       "      <td>https://www.linkedin.com/in/asfetaw-abera-54b0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meng Zhao</td>\n",
       "      <td>/in/mzhao15</td>\n",
       "      <td>Data Engineering Fellow at Insight Data Science</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>Data Engineer at Vanguard</td>\n",
       "      <td>https://www.linkedin.com/in/mzhao15/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adam Bethke</td>\n",
       "      <td>/in/adambethke</td>\n",
       "      <td>Data Engineer II at DigitalOcean</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Engineer @ DigitalOcean</td>\n",
       "      <td>https://www.linkedin.com/in/adambethke/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jiazhen Zhu</td>\n",
       "      <td>/in/jiazhen-zhu</td>\n",
       "      <td>Data Engineer at Walmart Global Tech</td>\n",
       "      <td>Reston, VA</td>\n",
       "      <td>Data Engineer / Machine Learning Engineer at W...</td>\n",
       "      <td>https://www.linkedin.com/in/jiazhen-zhu/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E. Jose Perales</td>\n",
       "      <td>/in/e-jose-perales-05b1a773</td>\n",
       "      <td>Data Engineer at The Chronicle of Higher Educ...</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Data Engineer at Interos Inc</td>\n",
       "      <td>https://www.linkedin.com/in/e-jose-perales-05b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Venkat Nelluri</td>\n",
       "      <td>/in/vnelluri</td>\n",
       "      <td>Data Engineer at Citi</td>\n",
       "      <td>Dallas-Fort Worth Metroplex</td>\n",
       "      <td>Data Engineer at Albertsons Companies</td>\n",
       "      <td>https://www.linkedin.com/in/vnelluri/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                           url  \\\n",
       "0             Vina Zhu        /in/vina-zhu-4986451a4   \n",
       "1   Murali Subramanian                /in/musubr0298   \n",
       "2      Bitthal Khaitan  /in/bitthal-khaitan-48846318   \n",
       "3        Jianfang Chen   /in/jianfang-chen-2286a31b1   \n",
       "4    Charishma Ravoori                /in/charishmar   \n",
       "5        Mahdieh Taher              /in/mahdiehtaher   \n",
       "6          Alper Tosun      /in/alper-tosun-bba82467   \n",
       "7   Alexandra Putilina                 /in/putilinaa   \n",
       "8        Asfetaw Abera   /in/asfetaw-abera-54b0a2185   \n",
       "9            Meng Zhao                   /in/mzhao15   \n",
       "10         Adam Bethke                /in/adambethke   \n",
       "11         Jiazhen Zhu               /in/jiazhen-zhu   \n",
       "12     E. Jose Perales   /in/e-jose-perales-05b1a773   \n",
       "13      Venkat Nelluri                  /in/vnelluri   \n",
       "\n",
       "                                          current_job  \\\n",
       "0                       Data Engineer at Slalom Build   \n",
       "1                         Data Engineer at Searce Inc   \n",
       "2                         Data Engineer at CVS Health   \n",
       "3                                    Data Engineering   \n",
       "4             Data Engineer at Lowe's Companies, Inc.   \n",
       "5                          Data Engineer at ViacomCBS   \n",
       "6    Data Management Analyst at Fannie Mae - ...th...   \n",
       "7        Data Engineer Fellow at Insight Data Science   \n",
       "8    Data Science Fellow at The Data Incubator - C...   \n",
       "9     Data Engineering Fellow at Insight Data Science   \n",
       "10                   Data Engineer II at DigitalOcean   \n",
       "11               Data Engineer at Walmart Global Tech   \n",
       "12   Data Engineer at The Chronicle of Higher Educ...   \n",
       "13                              Data Engineer at Citi   \n",
       "\n",
       "                        location  \\\n",
       "0                  Arlington, VA   \n",
       "1                     Austin, TX   \n",
       "2    Dallas-Fort Worth Metroplex   \n",
       "3                  United States   \n",
       "4                 Germantown, MD   \n",
       "5         San Francisco Bay Area   \n",
       "6   Washington DC-Baltimore Area   \n",
       "7           Greater Seattle Area   \n",
       "8              Silver Spring, MD   \n",
       "9                  Baltimore, MD   \n",
       "10                Washington, DC   \n",
       "11                    Reston, VA   \n",
       "12                Washington, DC   \n",
       "13   Dallas-Fort Worth Metroplex   \n",
       "\n",
       "                                             headline  \\\n",
       "0                                       Data Engineer   \n",
       "1      Data Engineer at Searce Inc. | 2x GCP | 2x AWS   \n",
       "2     Data Engineer @ World’s largest Healthcare org!   \n",
       "3                          Data Engineer at Microsoft   \n",
       "4                                       Data Engineer   \n",
       "5                                       Data Engineer   \n",
       "6                         Data Engineer at Fannie Mae   \n",
       "7                              Data Engineer at H-E-B   \n",
       "8                Data Engineer at Caris Life Sciences   \n",
       "9                           Data Engineer at Vanguard   \n",
       "10                       Data Engineer @ DigitalOcean   \n",
       "11  Data Engineer / Machine Learning Engineer at W...   \n",
       "12                       Data Engineer at Interos Inc   \n",
       "13              Data Engineer at Albertsons Companies   \n",
       "\n",
       "                                                fetch  \n",
       "0     https://www.linkedin.com/in/vina-zhu-4986451a4/  \n",
       "1             https://www.linkedin.com/in/musubr0298/  \n",
       "2   https://www.linkedin.com/in/bitthal-khaitan-48...  \n",
       "3   https://www.linkedin.com/in/jianfang-chen-2286...  \n",
       "4             https://www.linkedin.com/in/charishmar/  \n",
       "5           https://www.linkedin.com/in/mahdiehtaher/  \n",
       "6   https://www.linkedin.com/in/alper-tosun-bba82467/  \n",
       "7              https://www.linkedin.com/in/putilinaa/  \n",
       "8   https://www.linkedin.com/in/asfetaw-abera-54b0...  \n",
       "9                https://www.linkedin.com/in/mzhao15/  \n",
       "10            https://www.linkedin.com/in/adambethke/  \n",
       "11           https://www.linkedin.com/in/jiazhen-zhu/  \n",
       "12  https://www.linkedin.com/in/e-jose-perales-05b...  \n",
       "13              https://www.linkedin.com/in/vnelluri/  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.forward()\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
